{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet50\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import AutoModel, AutoTokenizer, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm, trange\n",
    "from time import perf_counter\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = \"/home/user/Desktop/RakutenMultimodalClassification/images/image_train/\"\n",
    "\n",
    "class ResNetDataset(Dataset):\n",
    "    def __init__(self, df, label_to_id, train=False, text_field=\"designation\", label_field=\"class\", image_path_field=\"imageid\", product_id_field='productid'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.label_to_id = label_to_id\n",
    "        self.train = train\n",
    "        self.text_field = text_field\n",
    "        self.label_field = label_field\n",
    "        self.image_path_field = image_path_field\n",
    "        self.product_id_field = product_id_field\n",
    "\n",
    "        # ResNet-50 settings\n",
    "        self.img_size = 224\n",
    "        self.mean, self.std = (\n",
    "            0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "\n",
    "        self.train_transform_func = transforms.Compose(\n",
    "                [transforms.RandomResizedCrop(self.img_size, scale=(0.5, 1.0)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(self.mean, self.std)\n",
    "                    ])\n",
    "\n",
    "        self.eval_transform_func = transforms.Compose(\n",
    "                [transforms.Resize(256),\n",
    "                    transforms.CenterCrop(self.img_size),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(self.mean, self.std)\n",
    "                    ])\n",
    "\n",
    "                    \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.df.at[index, self.text_field])\n",
    "        label = self.label_to_id[self.df.at[index, self.label_field]]\n",
    "        img_path = IMAGE_FOLDER + f\"image_{self.df.at[index, self.image_path_field]}_product_{self.df.at[index, self.product_id_field]}.jpg\"\n",
    "\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        if self.train:\n",
    "          img = self.train_transform_func(image)\n",
    "        else:\n",
    "          img = self.eval_transform_func(image)\n",
    "\n",
    "        return text, label, img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetFeatureModel(nn.Module):\n",
    "    def __init__(self, output_layer):\n",
    "        super().__init__()\n",
    "        self.output_layer = output_layer\n",
    "        pretrained_resnet = resnet50(pretrained=True)\n",
    "        self.children_list = []\n",
    "        for n,c in pretrained_resnet.named_children():\n",
    "            self.children_list.append(c)\n",
    "            if n == self.output_layer:\n",
    "                break\n",
    "\n",
    "        self.net = nn.Sequential(*self.children_list)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BertResNetModel(nn.Module):\n",
    "    def __init__(self, num_labels, text_pretrained='jinaai/jina-embeddings-v3'):\n",
    "        super().__init__()\n",
    "        self.text_encoder = AutoModel.from_pretrained(text_pretrained, trust_remote_code=True)\n",
    "        self.visual_encoder = ResNetFeatureModel(output_layer=\"avgpool\")\n",
    "        self.image_hidden_size = 2048\n",
    "        self.classifier = nn.Linear(self.text_encoder.config.hidden_size + self.image_hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, text, image):\n",
    "        text_feature = self.text_encoder.encode(text, convert_to_tensor=True)\n",
    "        img_feature = self.visual_encoder(image)\n",
    "        \n",
    "        features = torch.cat((text_feature, img_feature), 1)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "/home/user/Desktop/RakutenMultimodalClassification/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/Desktop/RakutenMultimodalClassification/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "num_out_labels = 27\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "resnet_model = BertResNetModel(num_labels=num_out_labels)\n",
    "resnet_model = resnet_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "# take only 10% of data \n",
    "df_small = df.sample(frac=0.1)\n",
    "df_train,df_val = train_test_split(df_small, test_size=0.2, stratify=df_small['class'])\n",
    "\n",
    "label_to_id = {lab:i for i, lab in enumerate(df_train['class'].sort_values().unique())}\n",
    "id_to_label = {v:k for k,v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 300\n",
    "warmup_steps = 1000\n",
    "max_seq_length = 128\n",
    "PATIENCE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training loop\n",
    "#set_seed(seed_val)\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "train_dataset = ResNetDataset(df=df_train, label_to_id=label_to_id, train=True, text_field=\"designation\", label_field=\"class\", image_path_field=\"imageid\", product_id_field='productid')\n",
    "val_dataset = ResNetDataset(df=df_val, label_to_id=label_to_id, train=False, text_field=\"designation\", label_field=\"class\", image_path_field=\"imageid\", product_id_field='productid')\n",
    "\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)        \n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                    batch_size=batch_size, \n",
    "                    sampler=train_sampler)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "\n",
    "t_total = len(train_dataloader) * num_train_epochs\n",
    "\n",
    "optimizer = AdamW(resnet_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = get_scheduler(name=\"cosine\", optimizer=optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "start = perf_counter()\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch_num in trange(num_train_epochs, desc='Epochs'):\n",
    "    # Training\n",
    "    resnet_model.train()\n",
    "    epoch_total_loss = 0\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc='Batch'):        \n",
    "        b_text, b_labels, b_imgs = batch\n",
    "        b_labels = b_labels.to(device)\n",
    "        b_imgs = b_imgs.to(device)\n",
    "\n",
    "        resnet_model.zero_grad()\n",
    "        b_logits = resnet_model(text=b_text, image=b_imgs)\n",
    "        \n",
    "        loss = criterion(b_logits, b_labels)\n",
    "        epoch_total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    avg_loss = epoch_total_loss/len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    resnet_model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            b_text, b_labels, b_imgs = batch\n",
    "            b_labels = b_labels.to(device)\n",
    "            b_imgs = b_imgs.to(device)\n",
    "            \n",
    "            b_logits = resnet_model(text=b_text, image=b_imgs)\n",
    "            b_preds = torch.argmax(b_logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            val_loss = criterion(b_logits, b_labels)\n",
    "            val_total_loss += val_loss.item()\n",
    "            \n",
    "            val_preds.extend(b_preds)\n",
    "            val_labels.extend(b_labels.cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = val_total_loss/len(val_dataloader)\n",
    "    f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "    print('epoch =', epoch_num)\n",
    "    print('    epoch_loss =', epoch_total_loss)\n",
    "    print('    avg_epoch_loss =', avg_loss)\n",
    "    print('    avg_val_loss =', avg_val_loss)\n",
    "    print('    validation f1 weighted =', f1)\n",
    "    print('    learning rate =', optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= PATIENCE:\n",
    "            print(f'Early stopping triggered after {epoch_num + 1} epochs')\n",
    "            break\n",
    "\n",
    "end = perf_counter()\n",
    "resnet_training_time = end - start\n",
    "print('Training completed in ', resnet_training_time, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
